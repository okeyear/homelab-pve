# This is a basic workflow to help you get started with Actions

name: "[ 02 ] Create new VirtualMachines"

# Controls when the workflow will run
on:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      runner:
        description: 'Github Action Runner/Agent'
        required: true
        default: self-hosted
        type: choice
        options:
          - self-hosted
          - ubuntu-latest

      vm_prefix:
        description: 'VM Name Prefix'
        required: true
        default: 'k8s-'
        type: string

      vm_template:
        description: 'VM Clone from Template'
        required: true
        default: almalinux9
        type: choice
        options:
          - ubuntu24.04
          - ubuntu22.04
          - debian13
          - debian12
          - almalinux10
          - almalinux9
          - almalinux8
          - centos7
          - centos9stream
          - alinux3
          - openEuler2403

      ip_list:
        description: 'VMs IP List'
        required: true
        default: '11,101,102'
        type: string

      vm_user:
        description: 'VM Guest: OS User'
        required: true
        default: vagrant
        type: choice
        options:
          - vagrant
          - root
env:
  TAILSCALE_HOST: ${{ vars.TAILSCALE_HOST }}
  TAILSCALE_NET: ${{ vars.TAILSCALE_NET }}
  # VM_TEMPLATE_ID: ${{ github.event.inputs.vm_template_id }} # vmæ¨¡æ¿çš„ID
  VM_PREFIX: ${{ github.event.inputs.vm_prefix }}
  VM_USER: ${{ github.event.inputs.vm_user }}
  CIDR: ${{ vars.CIDR }}  # vmbr0 vmbr1 çš„ç½‘æ®µ

  # MASTER_IP: 10.10.10.11
  # NODE01_IP: 10.10.10.101
  # NODE02_IP: 10.10.10.102

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  setup-vms:
    name: ðŸš€ Create VMs for ${{ github.event.inputs.vm_prefix }}
    # The type of runner that the job will run on
    runs-on: ${{ github.event.inputs.runner }}
    # runs-on: [self-hosted]
    # runs-on: ubuntu-latest
    permissions:
      id-token: write   # è®© GitHub é¢å‘ OIDC
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v5
            
      # åƒæ™®é€šå®˜æ–¹ action ä¸€æ ·ç”¨ with ä¼ å‚
      - uses: ./pipeline-template/actions/prepare-env
        # with:
        #   node-version: '22'      # æƒ³ä¼ å•¥å°±ä¼ å•¥
        #   python-version: '3.10'  # å›ºå®šç‰ˆæœ¬ä¹Ÿè¡Œ, è¿™ä¸ªæ˜¯ pipeline agentè¿è¡Œç”¨çš„,ä¸æ˜¯scfä¸šåŠ¡çŽ¯å¢ƒ
      
      - name: Get VM Template ID
        run: |
          cat > versions.txt <<'EOF'
          2003 alinux3
          2007 centos7
          2008 almalinux8
          2009 almalinux9
          20010 almalinux10

          2109 centos9stream
          21010 centos10stream

          2112 debian12
          2113 debian13

          2204 ubuntu22.04
          2403 openEuler2403
          2404 ubuntu24.04
          2604 ubuntu26.04
          EOF
          temp_id=$(grep "\s${{ github.event.inputs.vm_template }}$" versions.txt | awk '{print $1}')
          echo "VM_TEMPLATE_ID=$temp_id"      >> "$GITHUB_ENV"

      - name: Install tools
        run: sudo apt-get update -yq && sudo apt-get install -yq sshpass

      - name: Check if already ssh key-based
        id: check-ssh
        run: |
          set +e
          test -d ~/.ssh || mkdir -p ~/.ssh
          ssh-keyscan -H ${{ env.TAILSCALE_HOST }}.${{ env.TAILSCALE_NET }} >> ~/.ssh/known_hosts
          ssh -o BatchMode=yes -o ConnectTimeout=5  root@${{ env.TAILSCALE_HOST }}.${{ env.TAILSCALE_NET }} exit
          if [ $? -eq 0 ]; then
            echo "keyless=true" >> $GITHUB_OUTPUT
          else
            echo "keyless=false" >> $GITHUB_OUTPUT
          fi      


      
      # 1ï¸âƒ£  æŠŠ Runner æŽ¥å…¥ tailnet
      - name: setup Tailscale Connect (if needed)
        if: steps.check-ssh.outputs.keyless != 'true'
        uses: tailscale/github-action@v3
        with:
          oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }}
          oauth-secret:    ${{ secrets.TS_OAUTH_SECRET }}
          tags: tag:ci     # ä¸Ž ACL ä¸­çš„ tag ä¿æŒä¸€è‡´
          version: latest # https://pkgs.tailscale.com/stable/#static
          use-cache: 'true'

      # 2ï¸âƒ£  æ­£å¸¸é€šè¿‡ 100.x æˆ–ä¸»æœºåè®¿é—®è¿œç¨‹æœº
      - name: Remote command via SSH
        run: |
          # pveHost=$(tailscale status --json | jq -r '.Self.HostName' )
          # sudo tailscale up --advertise-tags=tag:gh --accept-routes --hostname=${pveHost}
          # tailscale status
          test -d ~/.ssh || mkdir -p ~/.ssh
          ssh-keyscan -H ${{ env.TAILSCALE_HOST }}.${{ env.TAILSCALE_NET }} >> ~/.ssh/known_hosts
          # ssh root@${{ env.TAILSCALE_HOST }}.${{ env.TAILSCALE_NET }} "qm list"

          cat > setup_vms.sh <<'EOF'
          # k8s controlplane 4C8G & worker node 8C12G
          # for i in ${{ env.MASTER_IP }} ${{ env.NODE01_IP }} ${{ env.NODE02_IP }}
          ips=${{ github.event.inputs.ip_list }}
          arr=(${ips//,/ })
          for i in ${arr[*]}
          do
            VM_ID=10${i##*.}
            echo VM_ID $VM_ID
            # CIDR=${i%.*} # '192.168.168' vmbr0 vmbr1 çš„ç½‘æ®µ
            echo CIDR ${{ env.VM_USER }}
            pct destroy ${VM_ID} --force
            qm shutdown ${VM_ID} --forceStop
            sleep 2
            qm destroy ${VM_ID} --purge
            qm clone ${{ env.VM_TEMPLATE_ID }} $VM_ID --full # å®Œæ•´å…‹éš†è¿˜æ˜¯é“¾æŽ¥å…‹éš†
            qm set $VM_ID --core $(test $VM_ID -ge 10000 && echo 4 || echo 2) \
                      --memory $(test $VM_ID -ge 10000 && echo 8192 || echo 4096) --name ${{ env.VM_PREFIX }}node${VM_ID}
            qm set $VM_ID --ipconfig0 ip=${{ env.CIDR }}.${i}/24,gw=${{ env.CIDR }}.1  # è®¾ç½®ip
            qm set $VM_ID --cipassword vagrant --ciuser ${{ env.VM_USER }} # è®¾ç½®ç”¨æˆ·å’Œå¯†ç ã€‚æ³¨æ„å¯†ç åœ¨è®¾ç½®ä¹‹åŽï¼Œä¼šè‡ªåŠ¨éšè—ã€‚
            ssh-keygen -f "$HOME/.ssh/known_hosts" -R "${{ env.CIDR }}.${i}"
            qm disk resize $VM_ID scsi0 40G # è®¾ç½®ç¡¬ç›˜
            tags=$(qm config 2009 | grep tag | awk '{print $2}' | sed "s@template@${{ env.VM_PREFIX }}@" )
            # qm set $VM_ID --delete tags
            qm set $VM_ID --tags "$tags"
            qm start $VM_ID
          done
          EOF

          cat setup_vms.sh

          # æŠŠæœ¬åœ°è„šæœ¬å¤åˆ¶è¿‡åŽ»å¹¶ç«‹å³æ‰§è¡Œ
          alias ssh='ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
          cat setup_vms.sh | ssh root@${{ env.TAILSCALE_HOST }}.${{ env.TAILSCALE_NET }} 'bash -s'



      # - uses: actions/checkout@v4

      # - name: Install OS base pkgs
      #   run: |
      #     sudo apt-get update --yes -qq
      #     sudo apt-get install --yes --no-install-recommends python3-pip unzip curl wget jq git build-essential -qq


      # - name: Set up Docker Buildx
      #   uses: docker/setup-buildx-action@v3    # å®‰è£… Docker Buildx å·¥å…·é“¾


      # - name: Debug
      #   run: |
      #     pwd
      #     ls
      #     qm list

    